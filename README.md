# ðŸ¥˜ Food Ingredient Detector and Recipe Recommender
This project uses a **YOLOv8 object detection model** trained on food/ingredient images to:

- Detect ingredients from a **photo** uploaded by the user.
- (Future extension) Recommend recipes based on detected ingredients using an LLM.

Built with:
- **FastAPI** backend.
- **Simple HTML frontend**.
- **MLflow** for experiment tracking.
- **Local YOLOv8 training**.

---

## ðŸ“¸ Quick Demo

1. User uploads a picture (e.g., of a salad or vegetables).
2. Server detects ingredients like **"Tomato", "Lettuce", "Onion"**.
3. *(Coming soon)* Server recommends recipes based on detected items.

---

## ðŸ“‚ Project Structure

```
food-recipe-mlops/
â”œâ”€â”€ app/                     # FastAPI App
â”‚   â”œâ”€â”€ main.py              # FastAPI routes
â”‚   â”œâ”€â”€ model_loader.py      # Load trained YOLO model
â”‚   â”œâ”€â”€ predictor.py         # Run prediction on uploaded image
â”‚   â”œâ”€â”€ templates/           # Frontend (HTML)
â”‚   â”‚   â””â”€â”€ upload.html
â”‚   â””â”€â”€ static/              # (Optional) CSS/JS for styling
â”œâ”€â”€ training/                # Training code
â”‚   â”œâ”€â”€ train.py             # Train YOLO model, log to MLflow
â”‚   |
â”œâ”€â”€ requirements.txt         # All Python dependencies
â”œâ”€â”€ README.md                # This file
â””â”€â”€ .gitignore               # Standard ignore file
```

---

## ðŸš€ How to Set Up and Run Locally

### 1. Clone the Repository

```bash
git clone <your-repo-url>
cd food-recipe-mlops
```

### 2. Install Python Dependencies

It is recommended to create a fresh environment:

```bash
conda create -n fooddetector python=3.10
conda activate fooddetector
pip install -r requirements.txt
```

**Key dependencies:**
- `fastapi`
- `uvicorn`
- `pillow`
- `ultralytics`
- `mlflow`
- `jinja2`

### 3. Start MLflow Server Locally

```bash
mlflow ui --port 5001
```

Visit the MLflow UI at: [http://127.0.0.1:5001/](http://127.0.0.1:5001/)

### 4. Train a YOLOv8 Model (If Needed)

```bash
python training/train.py
```

- âœ… Logs metrics and model automatically to MLflow.
- âœ… Saves the best model as `/runs/detect/train/weights/best.pt`.

### 5. (Optional) Log an Already Trained Model

If you already have a trained model (e.g., downloaded from Roboflow), you can manually log it:

```bash
python training/log_saved_model.py
```

- âœ… Manually logs and registers the model into the MLflow Model Registry.

### 6. Start the FastAPI Server

```bash
uvicorn app.main:app --reload
```

Visit the application at: [http://127.0.0.1:8000/](http://127.0.0.1:8000/)

- âœ… Upload a food image.
- âœ… View detected ingredients.

---

## ðŸ§  Key Features

- **Transfer Learning on YOLOv8**: Fast and accurate ingredient detection.
- **Ingredient Detection**: Works with real-world messy photos.
- **Simple Frontend**: Upload images easily.
- **FastAPI Backend**: Clean and scalable architecture.
- **MLflow Integration**:
    - Experiment tracking (losses, metrics).
    - Model artifact logging.
    - Model versioning.
- **Error Handling**: Prevents crashes during model logging or prediction.
- **Future Extension**: Connect to LLMs (e.g., OpenAI, Gemini) for recipe generation.

---

## ðŸ“Š Example Detected Ingredients Output

**Uploaded Image âž”**

**Detected Ingredients:**
- Tomato (98.5%)
- Bell Pepper (94.2%)
- Lettuce (89.3%)

---

## ðŸ”¥ Future Improvements

- Draw bounding boxes on the uploaded image.
- Recommend recipes based on detected ingredients.
- Add a cuisine selector (e.g., Indian, Keto, Vegan).
- Deploy to GCP with a custom domain and SSL (production-ready version).
- Add logging, monitoring, and alerts.

---

## ðŸ“š References

- [YOLOv8 Documentation](https://docs.ultralytics.com/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [MLflow Documentation](https://mlflow.org/)
- [Roboflow Datasets](https://roboflow.com/)
